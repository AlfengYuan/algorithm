#include "cvimodel_debug.hpp"
using namespace tpu_mlir::backend;

namespace cvi_debug {

static void usage() {
  std::cout<<"The following parameters are required: \n";
  std::cout<<"Paramter1: xxx.cvimodel \n";
  std::cout<<"Paramter2: xxx_tensor_info.txt, generated by codegen pass.\n";
  std::cout<<"Paramter3: input.npz.\n";
  std::cout<<"Paramter4: output.npz.\n";
  std::cout<<"Paramter5: ref.npz, compared with the debug output.npz.\n";
  std::cout<<"Paramter6: tolerance, default as 0.98,0.95 \n";
  std::cout << "Usage Example: \n";
  std::cout<<"cvimodel_debug mobilenet_v2_cv183x_int8_sym.cvimodel mobilenet_v2_cv183x_int8_sym_tensor_info.txt "
           <<"mobilenet_v2_in_f32.npz output_int8.npz mobilenet_v2_cv183x_int8_sym_tpu_outputs.npz 0.99,0.99 \n";
}

void run_debug(char *modelFile, char *infoFile, char *input_file, char *output_file) {
  std::vector<std::vector<uint8_t>> cmdbuf;
  std::vector<uint8_t> weight;
  model_info minfo;
  parseCvimodel(modelFile, cmdbuf, weight, minfo);
  setenv("SET_CHIP_NAME", minfo.chip.c_str(), 1);
  std::vector<std::vector<debug_info_t>> tpu_debug_infos;
  uint32_t lg_store_size = 16;
  parseTensorInfo(infoFile, tpu_debug_infos, lg_store_size);

  CVI_RT_HANDLE ctx = nullptr;
  CVI_RT_Init(&ctx);
  int num_inputs = minfo.inputs_gmem_info.size();
  assert(num_inputs <= 5);
  int io_mem_num = minfo.io_mem_num;
  uint32_t shared_gmem_size = minfo.shared_gmem_size;
  if (shared_gmem_size == 0) {
    shared_gmem_size += 16;
  }
  CVI_RT_MEM shared_mem = CVI_RT_MemAlloc(ctx, shared_gmem_size);
  CVI_RT_MEM weight_mem = CVI_RT_MemAlloc(ctx, weight.size() > 0 ? weight.size() : weight.size() + 16);
  //To avoid private_gmem_size = 0, give more 16 bytes memory.
  uint32_t private_gmem_size = minfo.private_gmem_size;
  if (private_gmem_size == 0) {
    private_gmem_size += 16;
  }
  CVI_RT_MEM private_mem = CVI_RT_MemAlloc(ctx, private_gmem_size);
  std::vector<CVI_RT_MEM> io_mems(io_mem_num);
  for (int i = 0; i < io_mem_num; i++) {
    io_mems[i] = CVI_RT_MemAlloc(ctx, minfo.io_sizes[i]);
  }
  uint64_t shared_paddr = CVI_RT_MemGetPAddr(shared_mem);
  uint64_t private_paddr = CVI_RT_MemGetPAddr(private_mem);
  uint64_t weight_paddr = CVI_RT_MemGetPAddr(weight_mem);
  std::vector<uint64_t> io_paddrs(io_mem_num);
  for (int i = 0; i < io_mem_num; i++) {
    io_paddrs[i] = CVI_RT_MemGetPAddr(io_mems[i]);
  }
  uint8_t *weight_vaddr = CVI_RT_MemGetVAddr(weight_mem);
  uint8_t *shared_vaddr = CVI_RT_MemGetVAddr(shared_mem);
  uint8_t *private_vaddr = CVI_RT_MemGetVAddr(private_mem);
  std::vector<uint8_t*> io_vaddrs(io_mem_num);
  for (int i = 0; i < io_mem_num; i++) {
    io_vaddrs[i] = CVI_RT_MemGetVAddr(io_mems[i]);
  }
  //copy weight
  memcpy(weight_vaddr, weight.data(), weight.size());
  CVI_RT_MemFlush(ctx, weight_mem);
  std::map<std::string, std::vector<float>> tensor_data; //tensor_name and data
  std::map<std::string, std::vector<size_t>> tensor_shapes; //tensor_name and data
  loadInput(std::string(input_file), io_vaddrs, minfo, tensor_data, tensor_shapes);
  for (int i = 0; i < io_mem_num; i++) {
    CVI_RT_MemFlush(ctx, io_mems[i]);
  }
  CVI_RT_ARRAYBASE addrs;
  memset(&addrs, 0x00, sizeof(CVI_RT_ARRAYBASE));
  addrs.gaddr_base0 = shared_paddr;
  addrs.gaddr_base1 = weight_paddr;
  addrs.gaddr_base2 = private_paddr;
  setIOArrayBase(addrs, io_paddrs, io_mem_num);
  //give extra memory to store local op output
  CVI_RT_MEM lg_mem = CVI_RT_MemAlloc(ctx, lg_store_size);
  uint64_t lg_paddr = CVI_RT_MemGetPAddr(lg_mem);
  uint8_t *lg_vaddr = CVI_RT_MemGetVAddr(lg_mem);
  CVI_RT_ARRAYBASE lg_addrs;
  lg_addrs.gaddr_base0 = lg_paddr;

  std::vector<bool> cpu_tpu_order = minfo.cpu_tpu_order;
  std::vector<cpu_func_info> cpu_func_infos = minfo.cpu_func_infos;
  int tpu_count = 0, cpu_count = 0;
  for (bool isTpu : cpu_tpu_order) {
    if (isTpu) {
      std::vector<std::vector<uint8_t>> slice_cmdbufs;
      //slice_cmdbufs.clear();
      splitCmdbuf(cmdbuf[tpu_count], slice_cmdbufs);
      std::vector<debug_info_t> tpu_debug_info = tpu_debug_infos[tpu_count];
      if (slice_cmdbufs.size() > tpu_debug_info.size()) {
        llvm::errs()<<"slice_cmdbufs.size() = "<<slice_cmdbufs.size()<<",tpu_debug_info.size():"<<tpu_debug_info.size()<<"\n";
        assert(0);
      }
      for (int i = 0; i < slice_cmdbufs.size(); i++) {
        run_fun(ctx, slice_cmdbufs[i], addrs, false);
        debug_info_t dinfo = tpu_debug_info[i];
        if (dinfo.ignore) {
          continue;
        }
        std::string name = dinfo.name;
        auto g_shape = dinfo.g_shape;
        int64_t gn = g_shape[0], gc = g_shape[1], gh = g_shape[2], gw = g_shape[3];
        if (tensor_shapes.find(name) == tensor_shapes.end()) {
          std::vector<size_t> shape = {(size_t)gn, (size_t)gc, (size_t)gh, (size_t)gw};
          tensor_shapes[name] = shape;
        }
        uint32_t count = g_shape[0] * g_shape[1] * g_shape[2] * g_shape[3];
        if (tensor_data.find(name) == tensor_data.end()) {
          std::vector<float> data(count);
          tensor_data[name] = data;
        }
        if (dinfo.inGroup) {
          //insert storeOp cmdbuf to store the local mem data
          CV18xx::instance(getChip(minfo.chip));
          auto lg_info = dinfo.lg_idx_slice;
          int64_t n_slice = lg_info[1], h_slice = lg_info[3];
          if (h_slice < gh) {
            //if slice h_dim, n_dim's slice should be 1
            if (n_slice != 1) {
              llvm::errs()<<"name:"<<name<<"\n";
              assert(0);
            }
          }
          CVIKERNEL_FMT_E fmt = getCviKernelFmt(dinfo.qtype);
          gaddr_t ga_dst = 0;
          cvi_backend_tl_store_stride(i, ga_dst, dinfo.laddr, n_slice, gc, h_slice, gw,
                                      gc, gh, gw, false, true, true, fmt, fmt);
          std::vector<uint8_t> store_cmdbuf;
          CV18xx::submit();
          CV18xx::read_cmdbuf(store_cmdbuf);
          run_fun(ctx, store_cmdbuf, lg_addrs, false);
          store_cmdbuf.clear();
          CVI_RT_MemInvld(ctx, lg_mem);
          //copy data to cpu
          copyLgData(tensor_data[name], lg_vaddr + ga_dst, dinfo);
        } else {
          //store global data
          auto memTypeIndx = (dinfo.gaddr >> 40) & 0x07;
          int64_t offset = dinfo.gaddr - (memTypeIndx << 40);
          if (memTypeIndx == 0) {
            CVI_RT_MemInvld(ctx, shared_mem);
            storeGlobalData(tensor_data[name], shared_vaddr, offset, dinfo.qtype, count, dinfo.qscale);
          } else if (memTypeIndx == 2) {
            CVI_RT_MemInvld(ctx, private_mem);
            storeGlobalData(tensor_data[name], private_vaddr, offset, dinfo.qtype, count, dinfo.qscale);
          } else {
            assert(memTypeIndx >= 3 && memTypeIndx <= 7);
            CVI_RT_MemInvld(ctx, io_mems[memTypeIndx - 3]);
            storeGlobalData(tensor_data[name], io_vaddrs[memTypeIndx - 3], offset, dinfo.qtype, count, dinfo.qscale);
          }
        }
      }
      tpu_count++;
    } else {
      //cpu routine
      cpu_func_info func_info = cpu_func_infos[cpu_count];
      std::vector<std::vector<float>> inputs;
      std::vector<std::vector<float>> outputs;
      for (auto i_info : func_info.inputs) {
        gaddr_t addr = i_info.gaddr;
        auto memTypeIndx = (addr >> 40) & 0x07;
        int64_t offset = addr - (memTypeIndx << 40);
        if (memTypeIndx == 0) {
          getCpuInput(inputs, shared_vaddr, offset, i_info);
        } else if (memTypeIndx == 1) {
          getCpuInput(inputs, weight_vaddr, offset, i_info);
        } else if (memTypeIndx == 2) {
          getCpuInput(inputs, private_vaddr, offset, i_info);
        } else {
          assert(memTypeIndx >= 3 && memTypeIndx <= 7);
          getCpuInput(inputs, io_vaddrs[memTypeIndx - 3], offset, i_info);
        }
      }
      //prepare output
      for (auto o_info : func_info.outputs) {
        std::vector<float> reserve_data(o_info.count);
        outputs.emplace_back(reserve_data);
      }
      //run cpu_function
      invoke(func_info, inputs, outputs);
      //map output to private_vaddr
      int num_output = func_info.outputs.size();
      for (int i = 0; i < num_output; i++) {
        io_mem_info o_info = func_info.outputs[i];
        std::string name = o_info.name;
        auto g_shape = o_info.g_shape;
        if (tensor_shapes.find(name) == tensor_shapes.end()) {
          tensor_shapes[name] = {(size_t)g_shape[0], (size_t)g_shape[1],
                                (size_t)g_shape[2], (size_t)g_shape[3]};
        }
        if (tensor_data.find(name) == tensor_data.end()) {
          std::vector<float> data(o_info.count);
          tensor_data[name] = data;
        }
        auto memTypeIndx = (o_info.gaddr >> 40) & 0x07;
        assert(memTypeIndx >= 2 && "CpuOp's output must in private memory or io_memory");
        if (memTypeIndx == 2) {
          getAndSaveCpuOutput(outputs[i], tensor_data[name], private_vaddr, o_info);
          CVI_RT_MemInvld(ctx, private_mem);
        } else {
          getAndSaveCpuOutput(outputs[i], tensor_data[name], io_vaddrs[memTypeIndx - 3], o_info);
          CVI_RT_MemInvld(ctx, io_mems[memTypeIndx - 3]);
        }
      }
      cpu_count++;
    }
  }

  saveResult(std::string(output_file), tensor_data, tensor_shapes);

  //release
  for (int i = 0; i < io_mem_num; i++) {
    CVI_RT_MemFree(ctx, io_mems[i]);
  }
  CVI_RT_MemFree(ctx, shared_mem);
  CVI_RT_MemFree(ctx, weight_mem);
  CVI_RT_MemFree(ctx, private_mem);
  CVI_RT_MemFree(ctx, lg_mem);
  CVI_RT_DeInit(ctx);
}
}



int main(int argc, char **argv) {
  if (argc < 6) {
    cvi_debug::usage();
    exit(-1);
  }
  cvi_debug::run_debug(argv[1], argv[2], argv[3], argv[4]);
  std::string output_file(argv[4]);
  std::string ref_file(argv[5]);
  std::string compare_cmd = "npz_tool.py compare " + output_file + " " + ref_file +  " --tolerance ";
  if (argc == 6) {
    compare_cmd += "0.98,0.95 --except - -vv";
  } else {
    assert(argc == 7);
    std::string tolerance(argv[6]);
    compare_cmd += (tolerance + " --except - -vv");
  }
  std::cout<<compare_cmd<<"\n";
  system(compare_cmd.c_str());
}
